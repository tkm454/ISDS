{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "996ac1c5",
   "metadata": {},
   "source": [
    "# Group 26: Introduction to Social Data Science (ISDS), exam project 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c4f85",
   "metadata": {},
   "source": [
    "## Can We Predict If a PGA Tour Player Won a Tournament and Their Earnings based on educational background?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf586b48",
   "metadata": {},
   "source": [
    "## <a id='TOC'>Table of Contents</a>\n",
    "<ol>\n",
    "<li><a href='#section_1'>Data Collection: Accessing stats on the PGA Tour website</a></li>\n",
    "<li><a href='#section_2'>Predicting winners with machine learning classification models</a></li>\n",
    "<li><a href='#section_3'>Predicting earnings per tournament based on college background</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d627195",
   "metadata": {},
   "source": [
    "## 1. <a id='section_1'>Data Collection: Accessing stats on the PGA Tour website </a>\n",
    "<a href='#TOC'>Back to table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ebec0",
   "metadata": {},
   "source": [
    "### Importing Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c4aaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a94888c",
   "metadata": {},
   "source": [
    "### Fetching data via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03214ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_stats(category: int):\n",
    "    \"\"\"\n",
    "    Retrieve available statistics within a specific category.\n",
    "    \n",
    "    Parameters:\n",
    "        category (int): The index of the category for which to retrieve statistics.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Information about the statistics within the specified category.\n",
    "    \"\"\"\n",
    "    X_API_KEY = \"da2-gsrx5bibzbb4njvhl7t37wqyl4\"\n",
    "    payload = {\n",
    "        \"operationName\": \"StatDetails\",\n",
    "        \"variables\": {\n",
    "            \"tourCode\": \"R\",\n",
    "            \"statId\": 2,\n",
    "            \"year\": 2023,\n",
    "            \"eventQuery\": None\n",
    "        },\n",
    "        \"query\": (\n",
    "            \"query StatDetails($tourCode: TourCode!, $statId: String!, $year: Int, $eventQuery: StatDetailEventQuery) {\\n\"\n",
    "            \"  statDetails(\\n\"\n",
    "            \"    tourCode: $tourCode\\n\"\n",
    "            \"    statId: $statId\\n\"\n",
    "            \"    year: $year\\n\"\n",
    "            \"    eventQuery: $eventQuery\\n\"\n",
    "            \"  ) {\\n\"\n",
    "            \"    tourCode\\n\"\n",
    "            \"    year\\n\"\n",
    "            \"    displaySeason\\n\"\n",
    "            \"    statId\\n\"\n",
    "            \"    statType\\n\"\n",
    "            \"    tournamentPills {\\n\"\n",
    "            \"      tournamentId\\n\"\n",
    "            \"      displayName\\n\"\n",
    "            \"    }\\n\"\n",
    "            \"    yearPills {\\n\"\n",
    "            \"      year\\n\"\n",
    "            \"      displaySeason\\n\"\n",
    "            \"    }\\n\"\n",
    "            \"    statTitle\\n\"\n",
    "            \"    statDescription\\n\"\n",
    "            \"    tourAvg\\n\"\n",
    "            \"    lastProcessed\\n\"\n",
    "            \"    statHeaders\\n\"\n",
    "            \"    statCategories {\\n\"\n",
    "            \"      category\\n\"\n",
    "            \"      displayName\\n\"\n",
    "            \"      subCategories {\\n\"\n",
    "            \"        displayName\\n\"\n",
    "            \"        stats {\\n\"\n",
    "            \"          statId\\n\"\n",
    "            \"          statTitle\\n\"\n",
    "            \"        }\\n\"\n",
    "            \"      }\\n\"\n",
    "            \"    }\\n\"\n",
    "            \"    rows {\\n\"\n",
    "            \"      ... on StatDetailsPlayer {\\n\"\n",
    "            \"        __typename\\n\"\n",
    "            \"        playerId\\n\"\n",
    "            \"        playerName\\n\"\n",
    "            \"        country\\n\"\n",
    "            \"        countryFlag\\n\"\n",
    "            \"        rank\\n\"\n",
    "            \"        rankDiff\\n\"\n",
    "            \"        rankChangeTendency\\n\"\n",
    "            \"        stats {\\n\"\n",
    "            \"          statName\\n\"\n",
    "            \"          statValue\\n\"\n",
    "            \"          color\\n\"\n",
    "            \"        }\\n\"\n",
    "            \"      }\\n\"\n",
    "            \"      ... on StatDetailTourAvg {\\n\"\n",
    "            \"        __typename\\n\"\n",
    "            \"        displayName\\n\"\n",
    "            \"        value\\n\"\n",
    "            \"      }\\n\"\n",
    "            \"    }\\n\"\n",
    "            \"  }\\n\"\n",
    "            \"}\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    req = requests.post(\"https://orchestrator.pgatour.com/graphql\", json=payload, headers={\"x-api-key\": X_API_KEY, 'name': 'Simon Knobelauch Hansen', 'email': 'Rfv228@alumni.ku.dk'})\n",
    "    stats_in_category = req.json()[\"data\"][\"statDetails\"][\"statCategories\"][category]\n",
    "    return stats_in_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31509a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK INFORMATION:\n",
    "# -----------------------------------------------------------------------------\n",
    "# The results computed from this notebook are used in the project\n",
    "# \"Can We Predict If a PGA Tour Player Won a Tournament in That Year and Their Earnings\n",
    "# based on educational background?\" the ourced from a run on 21st of August 2023.\n",
    "# Due to ongoing golf events in the 2023 PGA Tour, the season 2023 dataset on which the results are based will change slightly of run later. \n",
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796f7655",
   "metadata": {},
   "source": [
    "As an example, we can retrieve the available stats in SCORING (category 5). There are 9 categories in total (0-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa3fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_stats(category=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20f85a6",
   "metadata": {},
   "source": [
    "We move on to building a function which can retrieve and merge the golf stats we want: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75bdada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(id_list: list):\n",
    "\n",
    "    \"\"\"\n",
    "    Retrieve and merge statistics data based on a list of stat IDs.\n",
    "\n",
    "    Parameters:\n",
    "        id_list (list): List of stat IDs to retrieve data for.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Merged DataFrame containing statistics data.\n",
    "    \"\"\"\n",
    "    \n",
    "    X_API_KEY = \"da2-gsrx5bibzbb4njvhl7t37wqyl4\"\n",
    "    YEAR = 2023 # Change this to the year you want to retrieve data for\n",
    "    first_stat = True\n",
    "    \n",
    "    for stat_id in id_list:\n",
    "        payload = {\n",
    "            \"operationName\": \"StatDetails\",\n",
    "            \"variables\": {\n",
    "                \"tourCode\": \"R\",\n",
    "                \"statId\": stat_id,\n",
    "                \"year\": YEAR,\n",
    "                \"eventQuery\": None\n",
    "            },\n",
    "         \"query\": \"query StatDetails($tourCode: TourCode!, $statId: String!, $year: Int, $eventQuery: StatDetailEventQuery) {\\n  statDetails(\\n    tourCode: $tourCode\\n    statId: $statId\\n    year: $year\\n    eventQuery: $eventQuery\\n  ) {\\n    tourCode\\n    year\\n    displaySeason\\n    statId\\n    statType\\n    tournamentPills {\\n      tournamentId\\n      displayName\\n    }\\n    yearPills {\\n      year\\n      displaySeason\\n    }\\n    statTitle\\n    statDescription\\n    tourAvg\\n    lastProcessed\\n    statHeaders\\n    statCategories {\\n      category\\n      displayName\\n      subCategories {\\n        displayName\\n        stats {\\n          statId\\n          statTitle\\n        }\\n      }\\n    }\\n    rows {\\n      ... on StatDetailsPlayer {\\n        __typename\\n        playerId\\n        playerName\\n        country\\n        countryFlag\\n        rank\\n        rankDiff\\n        rankChangeTendency\\n        stats {\\n          statName\\n          statValue\\n          color\\n        }\\n      }\\n      ... on StatDetailTourAvg {\\n        __typename\\n        displayName\\n        value\\n      }\\n    }\\n  }\\n}\"  \n",
    "      }\n",
    "        page = requests.post(\"https://orchestrator.pgatour.com/graphql\", json=payload, headers={\"x-api-key\": X_API_KEY ,'name':'Simon Knobelauch Hansen', 'email':'Rfv228@alumni.ku.dk'})\n",
    "        page.raise_for_status()\n",
    "        data = page.json()[\"data\"][\"statDetails\"][\"rows\"]\n",
    "        \n",
    "        # For the first stat of the loop, we can not merge dataframes, so it is initialized here\n",
    "        if first_stat:\n",
    "            df = pd.DataFrame(data)\n",
    "            if df.empty: # Some stats have no data, giving empty dataframe, which is skipped\n",
    "                continue\n",
    "            col_names = [\"playerId\", \"playerName\", \"country\"]\n",
    "            for col in range(len(page.json()[\"data\"][\"statDetails\"][\"statHeaders\"])):\n",
    "                col_name = page.json()[\"data\"][\"statDetails\"][\"statTitle\"]+\"(\"+page.json()[\"data\"][\"statDetails\"][\"statHeaders\"][col]+\")\"\n",
    "                df[col_name] = df.stats.apply(lambda x: str(x[col]['statValue']).replace(\",\", \"\").replace(\"$\", \"\") if isinstance(x, list) and len(x) > 0 else None)\n",
    "                col_names.append(col_name)\n",
    "            df = df[col_names]\n",
    "            first_stat = False\n",
    "        \n",
    "        # Here all the subsequent stats are merged onto the dataframe\n",
    "        else:\n",
    "            df_temp = pd.DataFrame(data)\n",
    "            if df_temp.empty: # Some stats have no data, giving empty dataframe, which is skipped\n",
    "                continue\n",
    "            col_names = [\"playerId\", \"playerName\", \"country\"]\n",
    "            for col in range(len(page.json()[\"data\"][\"statDetails\"][\"statHeaders\"])):\n",
    "                col_name = page.json()[\"data\"][\"statDetails\"][\"statTitle\"]+\"(\"+page.json()[\"data\"][\"statDetails\"][\"statHeaders\"][col]+\")\"\n",
    "                df_temp[col_name] = df_temp.stats.apply(lambda x: str(x[col]['statValue']).replace(\",\", \"\").replace(\"$\", \"\") if isinstance(x, list) and len(x) > 0 else None)\n",
    "                col_names.append(col_name)\n",
    "            df_temp = df_temp[col_names]\n",
    "\n",
    "            df = pd.merge(df, df_temp, left_on=[\"playerId\", \"playerName\", \"country\"], right_on=[\"playerId\", \"playerName\", \"country\"], how=\"outer\")\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0dd3c7",
   "metadata": {},
   "source": [
    "Now, define a list of stat IDs that we want to include in our dataset. We provide an example below. Note, the length of the dataframe must equal the number of unique Player IDs to ensure that each row corresponds to one player. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970fc60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_stats = [\"02675\", \"02567\", \"02568\", \"02569\", \"02564\", \"101\", \"130\", \"402\", \"014\", \"108\", \"103\", \"300\", \"154\", \"138\", \"213\"]\n",
    "df = get_data(id_list=desired_stats)\n",
    "print(\"Length of df (%s) should be the amount of unique player ids which is: %s\" % (len(df), len(df.playerId.unique())))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b256bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37327dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column names you want to drop\n",
    "columns_to_drop = ['SG: Off-the-Tee(Measured Rounds)', 'SG: Approach the Green(Measured Rounds)', 'SG: Around-the-Green(Measured Rounds)', 'SG: Putting(Measured Rounds)', 'Scrambling(Par or Better)', 'Scrambling(Missed GIR)', 'Overall Putting Average(# of Putts)', 'Overall Putting Average(# of Holes)', 'Scoring Average (Actual)(Total Strokes)', 'Scoring Average (Actual)(Total Rounds)', 'Greens in Regulation Percentage(Greens Hit)', 'Greens in Regulation Percentage(# Holes)', 'Greens in Regulation Percentage(Relative/Par)', 'Top 10 Finishes(1st)', 'Top 10 Finishes(2nd)', 'Top 10 Finishes(3rd)', 'Hit Fairway Percentage(Possible Fairways)', 'Hit Fairway Percentage(Relative to Par)', 'Hit Fairway Percentage(Fairways Hit)', 'Driving Distance(Total Drives)', 'Driving Distance(Total Distance)', 'SG: Total(Total SG:T)', 'SG: Off-the-Tee(Avg)', 'SG: Approach the Green(Avg)', 'SG: Around-the-Green(Avg)']\n",
    "\n",
    "# Drop the specified columns\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Replace NaN with 0 in Top 10 \n",
    "df['Top 10 Finishes(Top 10)'].fillna(0, inplace=True)\n",
    "df['Top 10 Finishes(Top 10)'] = df['Top 10 Finishes(Top 10)'].astype(int)\n",
    "df['Scrambling(%)'] = df['Scrambling(%)'].str.rstrip('%').astype(float)\n",
    "df['Greens in Regulation Percentage(%)'] = df['Greens in Regulation Percentage(%)'].str.rstrip('%').astype(float)\n",
    "df['Hit Fairway Percentage(%)'] = df['Hit Fairway Percentage(%)'].str.rstrip('%').astype(float)\n",
    "\n",
    "# Loop through object columns starting from index 3 and try to convert them to integers\n",
    "for column in df.select_dtypes(include=['object']).iloc[:, 3:].columns:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce').astype('Int64', errors='ignore')\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = df.dtypes\n",
    "column_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42acc3b",
   "metadata": {},
   "source": [
    "Next up, we want to access the biographies of each player available on the website. We then want to merge the information retrieved from the bios on to the dataframe containing the desired stats for each player. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bb32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key for authentication\n",
    "X_API_KEY = \"da2-gsrx5bibzbb4njvhl7t37wqyl4\"\n",
    "\n",
    "# Define the payload for the GraphQL query\n",
    "payload = {\n",
    "    \"operationName\": \"PlayerDirectory\",\n",
    "    \"variables\": {\n",
    "        \"tourCode\": \"R\"\n",
    "    },\n",
    "    \"query\": \"\"\"\n",
    "        query PlayerDirectory($tourCode: TourCode!, $active: Boolean) {\n",
    "            playerDirectory(tourCode: $tourCode, active: $active) {\n",
    "                tourCode\n",
    "                players {\n",
    "                    id\n",
    "                    isActive\n",
    "                    firstName\n",
    "                    lastName\n",
    "                    shortName\n",
    "                    displayName\n",
    "                    alphaSort\n",
    "                    country\n",
    "                    countryFlag\n",
    "                    headshot\n",
    "                    playerBio {\n",
    "                        id\n",
    "                        age\n",
    "                        education\n",
    "                        turnedPro\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Send a POST request to the GraphQL API\n",
    "req = requests.post(\n",
    "    \"https://orchestrator.pgatour.com/graphql\",\n",
    "    json=payload,\n",
    "    headers={\"x-api-key\": X_API_KEY}\n",
    ")\n",
    "\n",
    "# Extract player data from the API response and create a DataFrame\n",
    "df_player_bio = pd.DataFrame(req.json()[\"data\"][\"playerDirectory\"])\n",
    "\n",
    "# Extract playerBio information from the DataFrame\n",
    "player_bio_list = []\n",
    "for i in range(len(df_player_bio)):\n",
    "    player_bio_list.append(df_player_bio.players.iloc[i][\"playerBio\"])\n",
    "df_player_bio = pd.DataFrame(player_bio_list)\n",
    "\n",
    "# Merge playerBio data with existing DataFrame using playerId as the key\n",
    "df = pd.merge(df, df_player_bio, left_on=\"playerId\", right_on=\"id\", how=\"left\")\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "df['age'] = df['age'].astype(int)\n",
    "df['turnedPro'] = df['turnedPro'].astype(int)\n",
    "df['Winner_dummy'] = df['Victory Leaders(Victories)'].apply(lambda x: 1 if x > 0 else 0) #Winner dummy\n",
    "df['Career Earnings(Money)'] = df['Career Earnings(Money)'].astype(float)\n",
    "\n",
    "# Convert specific non-values to NaN in the \"Education\" column\n",
    "non_values = ['non', 'na', 'n/a', 'unknown', 'None']  # List of non-values to convert\n",
    "df['education'] = df['education'].apply(lambda x: np.nan if x in non_values else x)\n",
    "\n",
    "# Replace NaN values with \"Outside the US\" in the \"Education\" column\n",
    "df['education'] = df['education'].fillna('outside the US')\n",
    "\n",
    "# Convert specific non-values to NaN in the \"Education\" column\n",
    "non_values = ['non', 'na', 'n/a', 'unknown', 'None']  # List of non-values to convert\n",
    "df['turnedPro'] = df['turnedPro'].apply(lambda x: np.nan if x in non_values else x)\n",
    "\n",
    "# Replace NaN values with \"Outside the US\" in the \"Education\" column\n",
    "df['turnedPro'] = df['turnedPro'].fillna('Amateur')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b216a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose descriptive statistics for selected variables\n",
    "variables_of_interest = ['SG: Total(Avg)', 'SG: Total(Measured Rounds)', 'Driving Distance(Avg)', 'Victory Leaders(Victories)', 'Top 10 Finishes(Top 10)', 'Money per Event Leaders(Money per event)']\n",
    "\n",
    "# Compute descriptive statistics for the selected variables\n",
    "stats = df[variables_of_interest].describe()\n",
    "\n",
    "rounded_stats = stats.apply(lambda x: round(x, 1))\n",
    "\n",
    "rounded_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style for the plots (optional)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a distribution plot for SG Total(Avg)\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "\n",
    "sns.histplot(data=df, x=\"SG: Total(Avg)\", kde=True)  # Create a histogram with KDE\n",
    "\n",
    "plt.title(\"Distribution Plot of SG Total(Avg)\")\n",
    "plt.xlabel(\"SG: Total(Avg)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig('SG_Total(Avg)_dist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b86d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(18, 14))  # Adjust the figure size as needed\n",
    "\n",
    "# Create a heatmap of the correlation matrix\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "\n",
    "plt.title(\"Correlation Heatmap of Variables\")\n",
    "plt.savefig('correlation_heatmap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8bbad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['Victory Leaders(Victories)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d36cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "ax = sns.catplot(\n",
    "    x=\"Winner_dummy\",\n",
    "    y=\"SG: Total(Avg)\",\n",
    "    kind=\"swarm\",\n",
    "    data=df,\n",
    "    size=3,\n",
    "    palette=\"Set1\"  # Use the custom colors\n",
    ")\n",
    "\n",
    "# Set labels and title\n",
    "ax.set(xlabel='', ylabel='SG: Total(Avg)')\n",
    "\n",
    "# Customize the aesthetics\n",
    "sns.despine()  # Remove spines\n",
    "plt.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.7)  # Add horizontal grid lines\n",
    "plt.xticks([0, 1], [\"Non-winners\", \"Winners\"])  # Customize x-axis labels\n",
    "plt.savefig(\"SG_Total_avg_scatter.png\", dpi=300)  # Save the plot\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1712462",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(x=\"Winner_dummy\", y=\"age\", kind=\"swarm\", hue=\"country\", data=df, size=3)\n",
    "ax.set(xlabel='Winners vs non-winners', ylabel='age');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48686429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of players for each education\n",
    "country_counts = df['education'].value_counts()\n",
    "\n",
    "print(country_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad57ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x='Winner_dummy', y='SG: Total(Avg)', data=df)\n",
    "ax.set(xlabel='Non-winner vs winners', ylabel='SG: Total(Avg)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a35590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['SG: Total(Avg)'].dtype)\n",
    "print(df['Career Earnings(Money)'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8d4e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the size of the plot\n",
    "plt.figure(figsize=(8, 6))  # Adjust width and height as needed\n",
    "\n",
    "# Create the lmplot with adjusted size\n",
    "ax = sns.lmplot(x='SG: Total(Avg)', y='Career Earnings(Money)', data=df, height=6, aspect=1.2)\n",
    "\n",
    "# Set labels for the plot\n",
    "ax.set(xlabel='SG: Total(Avg)', ylabel='Career Earnings(Money)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, vars = ['SG: Total(Avg)', 'Career Earnings(Money)', 'Winner_dummy', 'age'] ,height=4, size=2); # make hist and scatter for all numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e212c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the size of the plot\n",
    "plt.figure(figsize=(8, 6))  # Adjust width and height as needed\n",
    "\n",
    "# Create a bar plot for distribution of top ten finishes\n",
    "ax = sns.countplot(x='Top 10 Finishes(Top 10)', data=df, palette='rocket')\n",
    "\n",
    "# Set labels for the plot\n",
    "ax.set(xlabel='Top 10 Finishes', ylabel='Count')\n",
    "plt.title('Distribution of Top 10 Finishes')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c7a54",
   "metadata": {},
   "source": [
    "## 2. <a id='section 2'>Predicting winners with machine learning models: Classification </a>\n",
    "<a href='#TOC'>Back to table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9612c404",
   "metadata": {},
   "source": [
    "The goal of this section is to use machine learning methods to predict if a player has won a tournament or not. For this purpose, we use a range of machine learning methods based on supervised learning to find the model with the best prediction accuracy. \n",
    "\n",
    "I.e. the goal is learning a prediction rule for labelled data. Out target is categorial; the player has either won or not won a tournament. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4f3fab",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1708181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages and modules from SciKitLearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb815ab",
   "metadata": {},
   "source": [
    "### Prepare data for classification with partioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570460a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features (X): Define the features that we will use to predict the target variable\n",
    "X = df.drop(columns=['playerId','Winner_dummy', 'playerName', 'country', 'education', 'Victory Leaders(Victories)', 'Money per Event Leaders(Money per event)'])\n",
    "\n",
    "# Target variable (y): 'Winner_dummy' column\n",
    "y = df['Winner_dummy']\n",
    "\n",
    "# Split the data into development and test data\n",
    "\n",
    "# SPLIT INTO DEVELOPMENT (2/3) AND TEST DATA (1/3)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=1/3, random_state=42)\n",
    "\n",
    "# SPLIT DEVELOPMENT INTO TRAIN (1/3) AND VALIDATION (1/3)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=1/2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d0d2ae",
   "metadata": {},
   "source": [
    "### Logistic regression classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed76ad4",
   "metadata": {},
   "source": [
    "We start out testing a plain logistic regression model, which gives us an accuracy of 80.9% on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0605f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model on train data, evaluate on test data\n",
    "clf = LogisticRegression(random_state=42) # Note: try default values\n",
    "\n",
    "clf.fit(X_train, y_train) # Model training\n",
    "\n",
    "y_hat_test = clf.predict(X_test) # Use model to predict test target\n",
    "y_hat_train = clf.predict(X_train) # Predictions on training data\n",
    "\n",
    "accuracy_test = (y_hat_test == y_test).mean() # Evaluate performance on test data\n",
    "accuracy_train = (y_hat_train == y_train).mean() # Evaluate performance on training data\n",
    "\n",
    "print(f\"Accuracy on test data: {accuracy_test:.3f}\")\n",
    "print(f\"Accuracy on training data: {accuracy_train:.3f}\")\n",
    "\n",
    "# Evaluate performance using classification report\n",
    "report = classification_report(y_test, y_hat_test)\n",
    "roc_auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(f\"ROC AUC score: {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28ef929",
   "metadata": {},
   "source": [
    "Logistic Regression classifier, Lasso (L1) regularization and Ridge (L2) regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054a48f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "pipe_lr = make_pipeline(\n",
    "    PolynomialFeatures(include_bias=True),\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(random_state=42, penalty = 'l1', C=1.0, solver='saga') # Change to penalty='l2' for Ridge regularization\n",
    ")\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_test = pipe_lr.predict(X_test)\n",
    "y_pred_train = pipe_lr.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "report = classification_report(y_test, y_pred_test)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, pipe_lr.predict_proba(X_test)[:, 1]) # Use pipe_lr for prediction\n",
    "\n",
    "print(f\"Accuracy on test data: {accuracy_test:.3f}\")\n",
    "print(f\"Accuracy on training data: {accuracy_train:.3f}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "print(f\"ROC AUC score: {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2fa72d",
   "metadata": {},
   "source": [
    "K-fold cross validation to optimize hyperparameter C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of lambdas\n",
    "lambdas = np.linspace(0.1, 300, 60) \n",
    "\n",
    "# SETUPa\n",
    "kfolds = KFold(n_splits=10)\n",
    "folds = list(kfolds.split(X_dev, y_dev))\n",
    "\n",
    "# Outer loop: lambdas\n",
    "accCV = []\n",
    "for lambda_ in lambdas:    \n",
    "    \n",
    "    # Inner loop: folds\n",
    "    accCV_ = []    \n",
    "    for train_idx, val_idx in folds:\n",
    "    \n",
    "        # Reset indices for training and validation data\n",
    "        X_train, y_train = X_dev.iloc[train_idx], y_dev.iloc[train_idx]\n",
    "        X_val, y_val = X_dev.iloc[val_idx], y_dev.iloc[val_idx]\n",
    "        \n",
    "        # Train model and compute accuracy on validation fold\n",
    "        pipe_lrCV = make_pipeline(PolynomialFeatures(),\n",
    "                                StandardScaler(),\n",
    "                                LogisticRegression(random_state=42, penalty='l1', C=lambda_, solver='saga'))  # change to \"penalty = 'l2' for l2 regularization\"\n",
    "        pipe_lrCV.fit(X_train, y_train)\n",
    "        accCV_.append(accuracy_score(pipe_lrCV.predict(X_val), y_val))  \n",
    "        \n",
    "    # Store result    \n",
    "    accCV.append(accCV_) \n",
    "    \n",
    "# Convert to DataFrame\n",
    "lambdaCV = pd.DataFrame(accCV, index=lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE OPTIMAL HYPERPARAMETERS (mean of accuracy across folds)\n",
    "optimal_lambda = lambdaCV.mean(axis=1).nlargest(1)\n",
    "print(\"Optimal lambda and optimal accuracy: \", optimal_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfda08c",
   "metadata": {},
   "source": [
    "Training the model the with optimal hypeparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3969327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE OPTIMAL HYPERPARAMETERS (mean of accuracy across folds)\n",
    "optimal_lambda = lambdaCV.mean(axis=1).nlargest(1)\n",
    "\n",
    "# RETRAIN/RE-ESTIMATE MODEL USING OPTIMAL HYPERPARAMETERS AND COMPARE PERFORMANCE\n",
    "pipe_lrCV = make_pipeline(PolynomialFeatures(), \n",
    "                             StandardScaler(),\n",
    "                             LogisticRegression(C=optimal_lambda.index[0], random_state=42, penalty='l1', solver='saga'))\n",
    "\n",
    "pipe_lrCV.fit(X_dev,y_dev) #fit optimal lambda to entire development set\n",
    "\n",
    "models = {'LogReg': pipe_lr, 'LogRegCV': pipe_lrCV}\n",
    "for name, model in models.items():\n",
    "    score = accuracy_score(model.predict(X_test),y_test)\n",
    "    print(name,round(score,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33188c1",
   "metadata": {},
   "source": [
    "Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c014db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "train_sizes, train_scores, test_scores = \\\n",
    "    learning_curve(estimator=pipe_lrCV,\n",
    "                   X=X_dev,\n",
    "                   y=y_dev,\n",
    "                   train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                   scoring='accuracy',                 \n",
    "                   cv=10,\n",
    "                   n_jobs=1)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std= np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std= np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.60, 1.03])\n",
    "plt.savefig('learning_curve.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83248a2",
   "metadata": {},
   "source": [
    "Validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3ab165",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "train_scores, test_scores = validation_curve(\n",
    "                            estimator=pipe_lrCV,\n",
    "                            X=X_dev,\n",
    "                            y=y_dev,\n",
    "                            param_name='logisticregression__C',\n",
    "                            param_range=param_range,\n",
    "                            cv=10)\n",
    "\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std= np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std= np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(param_range, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\n",
    "plt.fill_between(param_range, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "plt.plot(param_range, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation accuracy')\n",
    "plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Parameter C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.7, 1.0])\n",
    "plt.savefig('validation_curve.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3656f148",
   "metadata": {},
   "source": [
    "Random forest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0d701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Classifier with specified parameters\n",
    "forest = RandomForestClassifier(\n",
    "    criterion='gini',\n",
    "    n_estimators=20,\n",
    "    random_state=1,\n",
    "    n_jobs=1)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d7283",
   "metadata": {},
   "source": [
    "## 3. <a id='section_3'>Predicting earnings per event based on college background</a>\n",
    "<a href='#TOC'>Back to table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab788a3c",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb161de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages relevant for the this seciton \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2281ce",
   "metadata": {},
   "source": [
    "### Preparing dataframe for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0911af56",
   "metadata": {},
   "source": [
    "Make dataframe and define features (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676295fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame\n",
    "earning_df = df.copy()\n",
    "\n",
    "# Remove rows with NaN values\n",
    "earning_df.dropna(inplace=True)\n",
    "\n",
    "# Y value for machine learning is the Money column\n",
    "Y = earning_df['Money per Event Leaders(Money per event)']\n",
    "\n",
    "# Removing the specified columns from the DataFrame\n",
    "columns_to_drop = ['Winner_dummy', 'playerId', 'playerName', 'country', 'education', 'Victory Leaders(Victories)', 'Money per Event Leaders(Money per event)', 'Career Earnings(Money)', 'Money per Event Leaders(Total money)', 'Top 10 Finishes(Top 10)', 'SG: Total(Total SG:P)']\n",
    "X = earning_df.drop(columns=columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e848e8",
   "metadata": {},
   "source": [
    "### Setting up a linear regression function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966dfbb9",
   "metadata": {},
   "source": [
    "Making a function that partitions data intro training and test data and then fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a8a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_reg(X, Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 10)\n",
    "    clf = LinearRegression().fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print('R-Squared on training set: {:.3f}'\n",
    "          .format(clf.score(X_train, y_train)))\n",
    "    print('R-Squared on test set {:.3f}'\n",
    "          .format(clf.score(X_test, y_test)))\n",
    "    \n",
    "    print('linear model coeff (w):\\n{}'\n",
    "         .format(clf.coef_))\n",
    "    print('linear model intercept (b): {:.3f}'\n",
    "         .format(clf.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c85d1",
   "metadata": {},
   "source": [
    "### Defining linear regression with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd0a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_reg(X, Y, regularization='none', alpha=1.0):\n",
    "    \n",
    "    # Convert any non-numeric data to numeric, handling errors with 'coerce'\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=10)\n",
    "    \n",
    "    if regularization == 'none':\n",
    "        clf = LinearRegression().fit(X_train, y_train)\n",
    "    elif regularization == 'lasso':\n",
    "        clf = Lasso(alpha=alpha, max_iter=100000000).fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    r2_train = clf.score(X_train, y_train)\n",
    "    r2_test = clf.score(X_test, y_test)\n",
    "    \n",
    "    print('R-Squared on training set: {:.3f}'.format(r2_train))\n",
    "    print('R-Squared on test set: {:.3f}'.format(r2_test))\n",
    "    \n",
    "    if regularization == 'none':\n",
    "        print('linear model coeff (w):\\n{}'.format(clf.coef_))\n",
    "        print('linear model intercept (b): {:.3f}'.format(clf.intercept_))\n",
    "    elif regularization == 'lasso':\n",
    "        print('lasso model coeff (w):\\n{}'.format(clf.coef_))\n",
    "        print('lasso model intercept (b): {:.3f}'.format(clf.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9e5521",
   "metadata": {},
   "source": [
    "Now, you can use the modified X and Y in your linear_reg function as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run regression\n",
    "linear_reg(X, Y)  # Without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f8ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run regression \n",
    "linear_reg(X, Y, regularization='lasso')  # With Lasso regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1abf630",
   "metadata": {},
   "source": [
    "### Introducing polynomial features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Polynomial Feature to improve R-Squared\n",
    "poly = PolynomialFeatures(2)\n",
    "poly = poly.fit(X)\n",
    "poly_earning = poly.transform(X)\n",
    "print(poly_earning.shape)\n",
    "\n",
    "# Creating a DataFrame with the polynomial features \n",
    "poly_earning = pd.DataFrame(poly_earning, columns = poly.get_feature_names(X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9431cec",
   "metadata": {},
   "source": [
    "Run regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff73744",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg(poly_earning, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dda54d",
   "metadata": {},
   "source": [
    "Polynomial regression with ridge regularizaiton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6591673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_reg_ridge(X, Y, al):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                   random_state = 10)\n",
    "    clf = Ridge(alpha = al).fit(X_train, y_train)\n",
    "\n",
    "    print('(poly deg 2 + ridge) R-squared score (training): {:.3f}'\n",
    "         .format(clf.score(X_train, y_train)))\n",
    "    print('(poly deg 2 + ridge) R-squared score (test): {:.3f}'\n",
    "         .format(clf.score(X_test, y_test)))\n",
    "    \n",
    "    print('(poly deg 2 + ridge) linear model coeff (w):\\n{}'\n",
    "         .format(clf.coef_))\n",
    "    print('(poly deg 2 + ridge) linear model intercept (b): {:.3f}'\n",
    "         .format(clf.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4be606",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg_ridge(poly_earning, Y, al = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf2e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg_ridge(poly_earning, Y, al = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe04c1d",
   "metadata": {},
   "source": [
    "### Cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13fc507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(X, Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 10)\n",
    "    clf = Ridge(alpha=100).fit(X_train, y_train)\n",
    "    scores = cross_val_score(clf, X, Y, cv=5)\n",
    "    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d2fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val(poly_earning, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6495eb6",
   "metadata": {},
   "source": [
    "### Fetching the regression output for use in the project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f9730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_earning_with_names(X, Y, education):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=10)\n",
    "    clf = Ridge().fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X)\n",
    "    y_pred = pd.Series(y_pred)\n",
    "\n",
    "    pred_data = pd.concat([X, y_pred], axis=1)\n",
    "    pred_name = pd.concat([pred_data, df[['education', 'playerName']]], axis=1)\n",
    "\n",
    "    selected_earnings = pred_name.loc[pred_name['education'] == education]\n",
    "    return selected_earnings  # Assuming the column name for target variable is 'Y'\n",
    "\n",
    "education_category = \"outside the US\"\n",
    "mean_predicted_earning = find_earning_with_names(X=poly_earning, Y=Y, education=education_category)\n",
    "print(f\"Mean predicted earning for education '{education_category}': {mean_predicted_earning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean\n",
    "mean_money_per_event = df[df['education'] == 'outside the US']['Money per Event Leaders(Money per event)'].mean()\n",
    "\n",
    "print(\"Mean of actual Money per Event:\", mean_money_per_event)\n",
    "\n",
    "mean_predicted_earning = mean_predicted_earning[mean_predicted_earning['education'] == 'outside the US'][0.].mean()\n",
    "\n",
    "print(\"Mean predicted earnings:\", mean_predicted_earning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
